# （六）特别篇：内存段式管理和页式管理

## 1. 两种内存管理机制介绍

在现代操作系统中，内存管理是至关重要的部分。内存分页作为一种内存管理机制，有其独特的优势和必要性，以至于现代操作系统普遍采取了内存分页管理机制。

### 1.1 分页与分段的概念

#### 1.1.1 内存分段（Segmentation）

分段是一种将内存划分为若干段的内存管理方式，每一段包含一组有意义的信息。一个进程占用一个或多个段，彼此之间互不干扰。段的描述信息存储在段描述符（Segment Descriptor）中，通过全局描述符表（Global Descriptor Table, GDT）进行管理。**分段最早是CPU为了支持多任务所推出的机制**。

- **段描述符**：每个段描述符包含该段的基地址、段限长、访问权限等信息。
- **段选择子（Segment Selector）**：用于指向段描述符，并包含段的特定信息。

#### 1.1.2 分页（Paging）

分页是一种将物理内存划分为固定大小的页（Page）的小块，每一页通常是4KB或更大。虚拟地址空间也被划分为同样大小的页框（Page Frame），这些页框与物理页进行映射。早期的分页机制下寻址效率不高，弱于分段机制，因为CPU没有在硬件层面上提供遍历，但是**现代CPU普遍已经在硬件层面上支持了分页机制（比如MMU、高速缓存中的TLB快表等）**，目前分页机制下寻址速度并不比CPU原生支持的分段机制差多少。

- **页表（Page Table）**：用于存储虚拟地址到物理地址的映射关系。
- **页目录（Page Directory）**：用于管理多个页表，形成多级页表结构。

**分页的实现步骤**：

1. 虚拟地址被分为页目录项、页表项和页内偏移。
2. CPU通过页目录和页表将虚拟地址转换为物理地址。
3. 如果页表未加载对应的页，CPU会触发缺页（Page Fault）中断，操作系统负责加载所需页。

### 1.2 两种管理机制的优缺点

#### 1.2.1 分段机制

1. **优点**：
   - **管理简单**：分段机制下，内存管理简单直接，段切换开销较小。
   - **低开销高效率**：CPU原生支持，段切换只需切换寄存器内容，效率极高。
2. **缺点**：
   - **外部碎片问题严重**：由于需要连续的大段内存，容易产生外部碎片，导致内存利用率低。
   - **动态分配困难**：难以动态调整内存大小（符合要求的大块连续内存不好找），程序需要事先申请足够的内存。

吐槽一句：分段机制的优缺点在《30天自制操作系统》里面可以说展现得淋漓尽致，跟着《30天自制操作系统》做过的这个项目的各位佬们肯定深有体会。《30天自制操作系统》里面所有的用户应用程序入口函数第一个操作就是malloc，要多少多少内存加载自身所需资源，不然都运行不了。

#### 1.2.2 分页机制

1. **优点**：
   - **内存利用率高**：分页允许非连续的内存分配，减少了内存碎片问题，尤其是外部碎片问题（按照每页4KB的粒度分配，浪费一点也浪费不了多少，对于现在消耗内存动不动500MB起步的软件来说，4K内存能干什么，浪费了就浪费了）。
   - **虚拟内存支持**：通过页表，可以将物理内存与虚拟内存进行映射，支持更大的虚拟地址空间。（可以多个虚拟地址映射同一个物理地址，这样虚拟内存就比物理内存还大了）
   - **内存保护**：每页都有独立的访问权限，可以实现细粒度（每页就4KB，当然细，除非你是内存不到1MB的单片机）的内存保护机制。
   - **灵活的内存分配**：操作系统可以动态分配和回收页（其实现代OS对于内存问题的策略就是，你需要内存，我就给你一页，不够再给一页，给到够为止，这简略了内存分配算法，但实际上就是这么个策略，这也是为什么不再需要应用程序自己malloc内存空间的原因），提供更灵活的内存管理。
2. **缺点**：
   - **页表开销大**：多级页表结构需要占用一定的内存空间，尤其在大内存环境下（4GB的内存，完全用页表管理，开销4MB，完全用两级页表也就是页目录表+页表，需要4MB + 4KB内存，但是这是完全管理的情况下，实际上绝大部分情况下两级页表的开销远小于只用一级页表）。
   - **页表查找开销**：每次内存访问需要进行多次页表查找，增加了访问延迟。现代CPU通过引入TLB（Translation Lookaside Buffer，快表）缓存页表来缓解这个问题。



### 1.3 为什么现代操作系统都采用内存分页机制？

1. **内存利用率与灵活性**：

   分页机制可以有效地解决内存碎片问题，提高内存利用率。操作系统可以将不连续的物理内存映射为连续的虚拟地址空间（只要在虚拟地址空间里面连续，对于进程来说就是一块完整的内存，寻址的事情自有CPU解决），方便进程的内存管理和动态扩展。

2. **虚拟内存支持**：

   分页使得虚拟内存的实现成为可能，程序可以使用比实际物理内存更大的地址空间。这对于运行大型应用程序和多任务操作系统至关重要。

3. **内存保护**：

   分页提供了细粒度的内存保护机制。每个页可以单独设置访问权限，防止进程之间的相互干扰，提高系统的稳定性和安全性。

4. **共享内存与进程间通信**：

   分页允许不同进程共享同一物理内存页，方便实现进程间通信和共享内存。操作系统可以将多个进程的虚拟地址映射到同一物理页。（最简单的实现进程间共享内存区域的策略就是这么做的）

5. **简化内存管理**：

   分页简化了操作系统的内存管理任务。通过页表和页目录，操作系统可以轻松实现内存分配、回收和交换，提高系统的整体效率。

总的来说，内存分页作为一种现代操作系统的内存管理机制，提供了高效的内存利用率、灵活的虚拟内存支持、精细的内存保护以及简化的内存管理方式。这些优势使得分页成为现代CPU和操作系统的首选内存管理机制。



## 2. 两种内存管理机制的实现

### 2.1 段式内存管理

段式内存管理中，每个段由段选择子和段描述符来管理和访问。

#### 2.1.1 段选择子

段选择子存储了以下信息：

- **段索引**：选择子中包含一个段描述符的索引，用于选择段描述符表（GDT或LDT）中的一个特定描述符。
- **TI位**：表示选择子指向的是GDT还是LDT。0表示GDT，1表示LDT。
- **RPL**：请求特权级（Requested Privilege Level），表示选择子请求的特权级。

示例段选择子的位划分如下：
- **位0-1**：RPL，0是最高特权级（内核级），3是最低特权级（用户级）
- **位2**：TI（0为GDT，1为LDT）
- **位3-15**：段索引

用C语言结构体和位域，可以表示为：

```c
// 段选择子
typedef struct {
    uint16_t rpl : 2;    // 位0-1: 请求特权级 (Requested Privilege Level, RPL，0是最高特权级，3是最低特权级)
    uint16_t ti : 1;     // 位2: 表指示符 (Table Indicator, 0=GDT, 1=LDT)
    uint16_t index : 13; // 位3-15: 段索引 (Segment Index)
} SegmentSelector;

```

#### 2.1.2 段描述符

段描述符包含了段的详细信息，如基地址、段界限和访问权限。一个64位段描述符的结构如下：

1. **段界限低16位（limit_low）**：
   - **位0-15**：段的界限低16位，用于指定段的大小。
   
2. **段基址低16位（base_low）**：
   - **位16-31**：段的基地址的低16位，用于指定段在内存中的起始地址。
   
3. **段基址中间8位（base_mid）**：
   - **位32-39**：段的基地址的中间8位。

4. **类型（type）**：
   - **位40-43**：描述段的类型，指示段的特性和用途。例如，代码段、数据段、系统段等。

5. **描述符类型（s）**：
   - **位44**：描述符类型位，指示该描述符是系统段（0）还是代码或数据段（1）。

6. **特权级（dpl）**：
   - **位45-46**：描述符特权级（Descriptor Privilege Level），指定该段的特权级别，从0到3，级别越低权限越高。

7. **段存在位（p）**：
   - **位47**：段存在位，指示该段是否在内存中（1表示存在，0表示不存在）。

8. **段界限高4位（limit_high）**：
   - **位48-51**：段的界限高4位，用于指定段的大小。

9. **可用位（avl）**：
   - **位52**：系统软件可用位，可由操作系统自行使用。

10. **64位代码段（l）**：
    - **位53**：64位代码段指示位，指示该段是否是64位代码段（1表示是）。

11. **默认操作大小（db）**：
    - **位54**：默认操作大小，0表示16位段，1表示32位段。

12. **粒度（g）**：
    - **位55**：粒度位，指示段界限的单位。0表示字节，1表示4KB。

13. **段基址高8位（base_high）**：
    - **位56-63**：段的基地址的高8位。

通过这些字段，段描述符可以精确描述一个段的大小、起始地址、类型、特权级以及其他属性。

用C语言结构体和位域，可以表示为：

```c
// 段描述符
typedef struct {
    uint64_t limit_low : 16;      // 位0-15: 段界限低16位
    uint64_t base_low : 16;       // 位16-31: 段基址低16位
    uint64_t base_mid : 8;        // 位32-39: 段基址中间8位
    uint64_t type : 4;            // 位40-43: 类型
    uint64_t s : 1;               // 位44: 描述符类型 (0=系统, 1=代码或数据)
    uint64_t dpl : 2;             // 位45-46: 特权级 (Descriptor Privilege Level)
    uint64_t p : 1;               // 位47: 段存在位
    uint64_t limit_high : 4;      // 位48-51: 段界限高4位
    uint64_t avl : 1;             // 位52: 可用位
    uint64_t l : 1;               // 位53: 64位代码段 (1=64位代码段)
    uint64_t db : 1;              // 位54: 默认操作大小 (0=16位段, 1=32位段)
    uint64_t g : 1;               // 位55: 粒度 (0=字节, 1=4KB)
    uint64_t base_high : 8;       // 位56-63: 段基址高8位
} SegmentDescriptor;

```



#### 2.1.3 CPU如何根据段选择子寻址

1. **解析段选择子**：CPU将段选择子解析为段索引、TI位和RPL。
2. **查找段描述符**：根据段索引和TI位，从GDT或LDT中查找相应的段描述符。
3. **计算线性地址**：将段基址加上段内偏移量，得到线性地址（段基址+偏移量）。



### 2.2 页式内存管理

分页是一种将内存分成固定大小的页和页框的管理方式，通过页表和页目录表进行地址转换。

用C语言结构体和位域解释如下，页目录表项和页表项都是32位的。

#### 2.2.1 页目录表项 (PDE)
```c
typedef struct {
    uint32_t present : 1;    // 位0: 是否存在 (1=存在, 0=不存在)
    uint32_t rw : 1;         // 位1: 读/写权限 (1=可读写, 0=只读)
    uint32_t us : 1;         // 位2: 用户/系统权限 (1=用户, 0=系统)
    uint32_t pwt : 1;        // 位3: 页面写通 (1=启用, 0=禁用)
    uint32_t pcd : 1;        // 位4: 页面缓存禁用 (1=启用, 0=禁用)
    uint32_t accessed : 1;   // 位5: 访问位 (1=已访问, 0=未访问)
    uint32_t reserved : 1;   // 位6: 保留位 (应为0)
    uint32_t page_size : 1;  // 位7: 页大小 (0=4KB, 1=4MB)
    uint32_t ignored : 1;    // 位8: 被忽略位
    uint32_t available : 3;  // 位9-11: 可用位 (操作系统保留)
    uint32_t table : 20;     // 位12-31: 页表地址 (物理地址右移12位)
} page_directory_entry_t;

```

#### 2.2.2 页表项 (PTE)
```c
typedef struct {
    uint32_t present : 1;    // 位0: 是否存在 (1=存在, 0=不存在)
    uint32_t rw : 1;         // 位1: 读/写权限 (1=可读写, 0=只读)
    uint32_t us : 1;         // 位2: 用户/超级用户权限 (1=用户, 0=超级用户，超级用户就是内核或者叫系统)
    uint32_t pwt : 1;        // 位3: 页面写通 (1=启用, 0=禁用)
    uint32_t pcd : 1;        // 位4: 页面缓存禁用 (1=启用, 0=禁用)
    uint32_t accessed : 1;   // 位5: 访问位 (1=已访问, 0=未访问)
    uint32_t dirty : 1;      // 位6: 脏位 (1=已修改, 0=未修改)
    uint32_t pat : 1;        // 位7: 页面属性表 (1=启用, 0=禁用)
    uint32_t global : 1;     // 位8: 全局页 (1=全局, 0=非全局)
    uint32_t available : 3;  // 位9-11: 可用位 (操作系统保留)
    uint32_t frame : 20;     // 位12-31: 页框地址 (物理地址右移12位)
} page_table_entry_t;

```

#### 2.2.3 CPU如何根据这些信息寻址

1. **解析线性地址**：将线性地址分为页目录索引、页表索引和页内偏移。
   - **页目录索引**：线性地址的高10位。
   - **页表索引**：线性地址的中间10位。
   - **页内偏移**：线性地址的低12位。
2. **查找页目录表**：根据页目录索引，从页目录表中查找对应的页目录表项（PDE）。
3. **查找页表**：根据页表索引，从页表中查找对应的页表项（PTE）。
4. **计算物理地址**：将页表项中的页框地址加上页内偏移，得到物理地址。

通过以上步骤，CPU可以将线性地址转换为物理地址，实现内存分页管理。



## 3. 两种管理机制涉及的硬件支持

### 3.1 段寄存器

段式内存管理依赖于CPU的硬件支持，主要就是使用段寄存器。

段寄存器用于存储当前正在使用的段选择子。常见的段寄存器有：

- **CS（代码段寄存器）**：存储代码段的段选择子。
- **DS（数据段寄存器）**：存储数据段的段选择子。
- **SS（堆栈段寄存器）**：存储堆栈段的段选择子。
- **ES、FS、GS（额外段寄存器）**：用于存储额外的数据段选择子，比如在HOS项目里面，我的GS里面存储的就是视频段的选择子。

段式内存管理的效率高，因为它是CPU原生支持的，寻址过程不需要其他硬件的参与。段基址和段界限都存储在CPU的段寄存器中，访问这些信息的开销非常低。这使得段式内存管理在某些场景下比分页机制更高效，特别是在频繁访问固定内存区域的情况下，而且寻址速度上来说，段式内存管理比页式内存管理还快，哪怕页式内存管理有了MMU这个专门的硬件支持，寻址速度上也不如段式内存管理。

### 3.2 MMU（内存管理单元）

MMU（Memory Management Unit，内存管理单元）是一种内置在CPU里面的硬件组件，负责管理和转换虚拟地址到物理地址。它在处理器和内存之间起着桥梁作用，使操作系统能够使用虚拟内存和分页机制。MMU的主要功能包括：

1. **地址转换**：将虚拟地址转换为物理地址。
2. **内存保护**：控制访问权限，防止非法访问。
3. **缓存控制**：管理缓存策略，优化内存访问速度。

MMU在CPU执行内存访问指令时，按照以下步骤工作：

1. **地址解析**：CPU生成虚拟地址（线性地址），并发送给MMU。
2. **页目录查找**：MMU根据虚拟地址的高位部分，从页目录中查找对应的页目录表项（PDE）。
3. **页表查找**：MMU根据虚拟地址的中间部分，从页表中查找对应的页表项（PTE）。
4. **地址转换**：MMU将页表项中的页框地址与虚拟地址的低位部分组合，生成物理地址。
5. **内存访问**：MMU将物理地址发送给内存控制器，完成内存访问操作。

现代CPU都有MMU，虚拟地址解析工作完全由MMU进行。

TLB（Translation Lookaside Buffer，标准翻译为 **后备缓冲** 实际上往往被称为 **快表**）是MMU中的一个高速缓存，用于存储最近使用的页表项。TLB的作用是加速地址转换过程，减少访问页表的时间开销。因为内存读写速度虽然在我们看来已经很快了，但是在CPU看来实在不行，CPU的高速缓存访问速度都是以纳秒计时的，**快表存在的意义就是节省MMU寻址的时间，提高寻址效率**。

**TLB的工作原理**：

1. **TLB命中**：当CPU生成一个虚拟地址时，MMU首先在TLB中查找。如果找到对应的页表项（TLB命中），MMU直接使用缓存中的物理地址，跳过页表查找过程。
2. **TLB未命中**：如果TLB中没有找到对应的页表项（TLB未命中），MMU会按照正常的页目录和页表查找流程，进行地址转换。同时，将新查找到的页表项缓存到TLB中，以便下次使用。

TLB是MMU的一部分，专门用于缓存最近使用的页表项，加速地址转换。MMU通过TLB来提高内存访问的效率，减少页表查找的时间开销。MMU和TLB的结合，使得虚拟内存和分页机制的性能得到了显著提升。

其实 **TLB的这一策略就是LRU算法的真实应用**。